{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebvqJaNU9bkH"
      },
      "source": [
        "# Elementy Inteligencji Obliczeniowej - Sieci Neuronowe\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Prowadzący:** Jakub Bednarek<br>\n",
        "**Kontakt:** jakub.bednarek@put.poznan.pl<br>\n",
        "**Materiały:** [Strona WWW](http://jakub.bednarek.pracownik.put.poznan.pl)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0tVMrm99g5w"
      },
      "source": [
        "## Uwaga\n",
        "\n",
        "* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n",
        "* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlq47LA0BuBB"
      },
      "source": [
        "## Cel ćwiczeń:\n",
        "- zapoznanie się z Keras subclassing API\n",
        "- stworzenie własnych modeli i warstw z wykorzystaniem Keras subclassing API\n",
        "- wykorzystanie podstawowych mechanizmów regularyzacji: Dropout i Batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxLU8paIDmUe"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scL5_bHTD-M7"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Layer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adadelta, RMSprop\n",
        "from tensorflow.python.keras import backend as K\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV_u-YBWEJ8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dea62db-f047-4385-e1e5-584ecd2931b1"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train[:, :, :, np.newaxis].astype('float32')\n",
        "x_test = x_test[:, :, :, np.newaxis].astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppmDSGoyFuJ9"
      },
      "source": [
        "## Tworzenie własnych modeli i warstw \n",
        "https://www.tensorflow.org/tutorials/customization/custom_layers\n",
        "\n",
        "https://www.tensorflow.org/guide/keras/custom_layers_and_models\n",
        "\n",
        "Przykładowy model z warstwami gęstymi dla danych MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViqotGlHGy9t"
      },
      "source": [
        "class DenseModel(Model):\n",
        "\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(DenseModel, self).__init__(name='my_model')\n",
        "    self.num_classes = num_classes\n",
        "    # Define your layers here.\n",
        "    self.dense_1 = Dense(512, input_shape=(784,), activation='relu')\n",
        "    self.dense_2 = Dense(512, activation='relu')\n",
        "    self.dense_3 = Dense(num_classes, activation='softmax')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Define your forward pass here,\n",
        "    # using layers you previously defined (in `__init__`).\n",
        "    x = self.dense_1(inputs)\n",
        "    x = self.dense_2(x)\n",
        "    return self.dense_3(x)\n",
        "\n",
        "model = DenseModel(num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFs-QBFtEp0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958cda65-472f-4f8a-a362-2cfcdf3306b9"
      },
      "source": [
        "model.compile(optimizer=RMSprop(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.3182 - accuracy: 0.9006\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0999 - accuracy: 0.9733\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0811 - accuracy: 0.9794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9c9b260240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axZWFRVEyPv7"
      },
      "source": [
        "Przykład własnej warstwy. Warstwa to po prostu funkcjonalny moduł do wielokrotnego używania, podczas gdy model to gotowe rozwiązanie dla danego problemu uczenia maszynowego (tzn. w Kerasie zazwyczaj kompletna sieć neuronowa), które udostępnia dodatkowo takie metody jak `fit`, `evaluate` i `predict`. Oczywiście można też budować modele/warstwy korzystające z innych modeli/warstw, API obu tych klas jest bardzo podobne.\n",
        "\n",
        "W poniższym kodzie, metoda `build` w `CustomLayer` jest wołana raz przed pierwszym wywołaniem `call` (zaimplementowane jest to w `__call__()`), co pozwala nam uzależnić liczbę wag warstwy od wymiaru wyjść z warstwy poprzedniej. Jeżeli odgórnie wiemy, ile wag ma mieć warstwa, to równie dobrze możemy je zainicjować w `__init__` tak jak wcześniej."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxVJBabOxkQS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "325beed7-1b21-4302-91c6-201f6f55a7b8"
      },
      "source": [
        "class CustomLayer(Layer):\n",
        "\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        self.output_dim = output_dim\n",
        "        super(CustomLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        self.kernel = self.add_weight(name='kernel',\n",
        "                                      shape=(int(input_shape[1]), self.output_dim),\n",
        "                                      initializer='uniform',\n",
        "                                      trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.kernel)\n",
        "\n",
        "\n",
        "class CustomModel(Model):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CustomModel, self).__init__(name='custom_model')\n",
        "        self.num_classes = num_classes\n",
        "        # Define your layers here.\n",
        "        self.dense_1 = CustomLayer(output_dim=512, input_shape=(784,))\n",
        "        self.dense_2 = CustomLayer(output_dim=512, input_shape=(512,))\n",
        "        self.dense_3 = CustomLayer(output_dim=num_classes, input_shape=(512,))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define your forward pass here,\n",
        "        # using layers you previously defined (in `__init__`).\n",
        "        x = self.dense_1(inputs)\n",
        "        x = K.relu(x)\n",
        "        x = self.dense_2(x)\n",
        "        x = K.relu(x)\n",
        "        x = self.dense_3(x)\n",
        "        x = K.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "model = CustomModel(num_classes=10)\n",
        "\n",
        "model.compile(optimizer=RMSprop(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=3)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.2851 - accuracy: 0.9132\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0968 - accuracy: 0.9707\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0646 - accuracy: 0.9798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9ad8f1c898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgtZzVYg1361"
      },
      "source": [
        "### Zadanie 1\n",
        "Na podstawie powyższego przykładu stwórz własny model kolejno składający się z:\n",
        "- warstwy konwolucyjnej (Conv2D): 32 filtry 3x3,\n",
        "- konwolucyjnej: 64 filtry 3x3,\n",
        "- warstwy MaxPooling (MaxPooling2D): 2x2\n",
        "- warstwy ukrytej gęstej (Dense): 128 neuronów,\n",
        "- warstwy wyjściowej.\n",
        "\n",
        "Ważne:\n",
        "- w każdej warstwie poza warstwą wyjściową funkcją aktywacji powinno być relu,\n",
        "- funkcja aktywacji dla warstwy wyjściowej to softmax,\n",
        "- między częścią konwolucyjną a gęstą trzeba spłaszczyć tensor przy pomocy warstwy `Flatten`,\n",
        "- w przykładzie jest wykorzystywana sieć gęsta (dane są spłaszczone), sieci z warstwami konwolucyjnymi muszą otrzymać tensor 4-wymiarowy, zakomentuj linie \"spłaszczające\" podczas wczytywania danych.\n",
        "```\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSJUzxAc15uZ"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYDLWjdseB4H"
      },
      "source": [
        "### Zadanie 2 \n",
        "Na podstawie powyższego przykładu stwórz model bloku ResNet:\n",
        "- w warstwach konwolucyjnych wykorzystaj padding='same', aby rozmiary tensorów się nie zmieniały,\n",
        "- tego modelu nie trzeba budować i uczyć, zostanie on wykorzystany w kolejnym zadaniu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAvsPOz-GxjY"
      },
      "source": [
        "![resnet](https://miro.medium.com/max/1000/1*6HDuqhUzP92iXhHoS0Wl3w.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yZ8yKmbee44"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prwjaEv2efs3"
      },
      "source": [
        "### Zadanie 3\n",
        "Zmodyfikuj model z zadania 1, zamieniając warstwy konwolucyjne na dwa modele bloku ResNet z zadania 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGQr50EafxSH"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3sOaUu3b77l"
      },
      "source": [
        "### Zadanie 4\n",
        "Wykorzystując Keras Subclassing API, napisz Autoenkoder dla zbioru danych MNIST.\n",
        "- stwórz osobny model Enkodera,\n",
        "- stwórz osobny model Dekodera,\n",
        "- połącz oba modele celem zbudowania Autoenkodera,\n",
        "- można korzystać z warstw gęstych, nie trzeba korzystać z konwolucji,\n",
        "- poprzednie zadania były przykładem klasyfikacji, w których wykorzystywana była funkcja błędu categorical_crossentropy (która jest stosowana dla wektorów reprezentujących rozkład prawdopodobieństwa), w przypadku Autoenkoderów model rekonstruuje dane wejściowe, więc najłatwiej wykorzystać mean square error (mse),\n",
        "- w związku z powyższym również wyjście sieci się różni, nie klasyfikujemy (y_train) tylko rekonstruujemy (x_train)\n",
        "\n",
        "https://blog.keras.io/building-autoencoders-in-keras.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyu4YijDcA13"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agFLqb3bUHNh"
      },
      "source": [
        "## Regularyzacja\n",
        "### Zadanie 5\n",
        "Rozszerz model stworzony w zadaniu 1 o dwie warstwy Dropout (Dropout - https://keras.io/api/layers/regularization_layers/dropout/):\n",
        "- jedna po warstwie MaxPooling (wartość współczynnika odrzucenia 0.25)\n",
        "- druga po gęstej warstwie ukrytej (Dense), wartość współczynnika odrzucenia 0.5.\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFqCcx1ZYMMt"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WgmXVZ0YSVg"
      },
      "source": [
        "### Zadanie 6\n",
        "Rozszerz model stworzony w zadaniu 1 o dwie warstwy Batch normalization (BatchNormalization - https://keras.io/layers/normalization/) po warstwach konwolucyjnych."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcmlyYOpYUyy"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp4DmjC8YVl_"
      },
      "source": [
        "### Zadanie 7\n",
        "Rozszerz model stworzony w zadaniu 1 o warstwy z zadań 5 i 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yDqgHMGYZZd"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoruuRfaYMqZ"
      },
      "source": [
        "### Zadanie 8 \n",
        "Porównaj modele stworzone w zadaniach 1, 5, 6, 7 na zbiorze danych MNIST. Stwórz wykresy z przebiegiem błędu funkcji celu i trafności klasyfikacji dla zbioru treningowego i walidacyjnego.\n",
        "Cztery wykresy:\n",
        "- błąd funkcji celu dla zbioru treningowego,\n",
        "- błąd funkcji celu dla zbioru walidacyjnego,\n",
        "- trafność klasyfikacji dla zbioru treningowego,\n",
        "- trafność klasyfikacji dla zbioru walidacyjnego\n",
        "\n",
        "Na każdym wykresie powinny być 4 przebiegi dla modeli z wszystkich zadań (1, 5, 6, 7), tak by łatwo można je było ze sobą wizualnie porównać.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eixxtPW8Ygyk"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}